{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing and Feature Extraction\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_text(text):\n    if isinstance(text, str):\n        tokens = word_tokenize(text.lower())\n        tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n        return ' '.join(tokens)\n    return \"\"\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sentiment Analysis\n\ndef train_sentiment_analysis_model(X, y):\n    vectorizer = TfidfVectorizer()\n    X_vectorized = vectorizer.fit_transform(X)\n    model = SVC(kernel='linear')\n    model.fit(X_vectorized, y)\n    return model, vectorizer\n\n# Sentiment Extraction\n\ndef extract_sentiment_word_or_phrase(text, sentiment, model, vectorizer):\n    vectorized_text = vectorizer.transform([text])\n    predicted_sentiment = model.predict(vectorized_text)[0]\n\n    if predicted_sentiment == sentiment:\n        tokens = word_tokenize(text.lower())\n        sentiment_words = [tokens[i] for i in range(len(tokens)) if tokens[i] in vectorizer.get_feature_names_out()]\n\n        if sentiment_words:\n            return ' '.join(sentiment_words)\n    return None\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load train and test CSV data\n\ntrain_data = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\ntrain_text_column = train_data['text']\ntrain_sentiment_column = train_data['sentiment']\ntrain_text_id_column = train_data['textID']\n\ntest_text_column = test_data['text']\ntest_sentiment_column = test_data['sentiment']\ntest_text_id_column = test_data['textID']\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove rows with missing values from train data\n\ntrain_data = train_data.dropna(subset=['text', 'sentiment'])\ntrain_text_column = train_data['text']\ntrain_sentiment_column = train_data['sentiment']\n\n# Preprocess train text column\n\npreprocessed_train_text = [preprocess_text(str(text)) for text in train_text_column]\n\n# Prepare training data for sentiment analysis model\n\nX_train = preprocessed_train_text\ny_train = train_sentiment_column\n\n# Remove rows with missing values in X_train and y_train\n\nX_train, y_train = zip(*((text, sentiment) for text, sentiment in zip(X_train, y_train) if text))\n\n# Convert y_train to a NumPy array\n\ny_train = np.array(y_train)\n\n# Train sentiment analysis model\n\nsentiment_model, vectorizer = train_sentiment_analysis_model(X_train, y_train)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model on test data and save the results to CSV\n\nresults = []\ncorrect_predictions = 0\ntotal_predictions = 0\n\nfor text_id, text, sentiment in zip(test_text_id_column, test_text_column, test_sentiment_column):\n    sentiment_word_or_phrase = extract_sentiment_word_or_phrase(str(text), sentiment, sentiment_model, vectorizer)\n    results.append({'textID': text_id, 'selected_text': sentiment_word_or_phrase})\n\nresults_df = pd.DataFrame(results)\nprint(results_df)","metadata":{},"execution_count":null,"outputs":[]}]}